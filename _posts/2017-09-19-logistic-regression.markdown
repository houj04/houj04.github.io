---
layout: post
title: "逻辑回归"
categories: mypost
---

# Logistic Regression

[TOC]

## 前言

开个新坑。最近遇到了一个“传统机器学习”的项目，预测某个用户对某个广告的点击率（CTR，click through rate）。这的确是一个古老的问题，典型的二分类（binary classification），最标准也是最常见的模型是逻辑回归（logistic regression）。正好赶上招聘季，发现现在的小朋友们的基础知识已经比我刚毕业的那个年代有了长足的进步，投机器学习岗位的随便一份简历里面都会写一些关于人工智能、机器学习、深度学习相关的项目经验和成果，至少是会堆一大堆术语上来。面试的时候让写一下逻辑回归的损失函数或者是求个梯度，已经不能算是“难为”了。

想了想，还是有必要整理一下，除了逻辑回归是怎么算的之外，还有一些挺有意思的问题。例如，为什么要“$\omega$乘以$x$再激活”，它是怎么和各种概率搅和在一起的，在某些教材和参考书上为什么把它叫做“对数几率回归”。

## 点击率预估

点击率预估是计算广告学里面一个重要的组成部分。在给用户展示广告的时候，不管是基于用户的搜索词（query），是基于用户正在访问的网页的页面内容和信息，还是基于用户最近浏览过的网页（或者说是用户兴趣），我们都能从广告库里面召回（recall）很多条广告。显然这里的问题有不止一个，例如，如何召回尽量少的广告，如何将广告排序展示给用户以获得最大的收益（简单的策略是将最昂贵的广告展示在最前面，然而用户不一定会点击，并且体验可能很差），等等。

点击率预估做了这样一件事情：通过大量用户的历史行为来预测当前单个用户对一大堆候选广告列表的每条广告的点击率。对于模型来说，给一个用户，给一个广告，要输出一个$0$到$1$之间的浮点数，表示这个用户点击这条广告的概率。后面可以用这个概率乘以广告的点击价格（出价，bid），就得到了收入的期望（expectation）。

说到“预估一个浮点数”，最容易想到的是线性回归（linear regression），假设有一大堆独立的变量（先不要管这些变量都是哪里来的），每个变量有一个权重（先不要管这些权重都是哪里来的），在预测的时候（先不要管怎么训练），看看要预测的样本（instance，或者叫sample）里面出现了哪些变量，把出现的变量的权重都一个个找出来，得到一大堆浮点数，然后全部加在一起，得到的肯定还是一个浮点数，作为最后的结果。

## 对数几率回归

先不管前面说的那三个“先不管”，线性回归还有一个问题，即，它只能保证预估出来的值是一个浮点数，而不能保证范围。我们要预测的是一个广告被点击的“概率”，是有范围的，必须在$0$到$1$之间。那么怎么才能把这两点结合到一起呢？简单，想个办法把概率这个$0$到$1$之间的数，给“映射”到实数域上就行了。假如我们能做这样的映射的话，在实际用的时候，先用线性回归模型计算出这个在实数域上面的预估值，然后做一个反映射，映射回$0$到$1$之间，不就搞定了么。

所以有人搞出了这么个东西，英文叫做odds，中文有的翻译成“几率”，有的翻译成“发生比”。其意义是某个事件发生和不发生的比率。举例来说，某个事件发生的概率是$p$，那么它不发生的概率是$1-p$，所以几率、发生比、odds是$p/(1-p)$。字母看着太别扭，也并不直观，那么找一个数带进去算算吧：例如某个事情的概率是三分之一（例如石头剪刀布的手势之一），那么它的odds是$(1/3)/(1-1/3)=1/2$。

显然，经过这样的处理之后，本来范围在$0$到$1$之间的概率$p$，变成了范围是$0$到$+\infty$的odds。再进一步，对上一步得到的结果再取个对数，范围就变成了$-\infty$到$+\infty$，也就是全体实数了。因此，我们对于最初的概率$p$，实际进行了“先转odds再取对数”的两个连续操作，这个操作被称为logit（很遗憾，这个操作似乎没有什么通用的中文翻译）。

（注：关于这个映射，不同参考资料上有不同的说法。有一些说$p$的范围是$0$到$1$之间，如果取个对数，变成$\ln p$的话，虽然范围扩大了，但是仍然不是全体实数，所以进一步修改，变成了$\ln\dfrac{p}{1-p}$。不管哪种说法和哪种“历程”比较准确，总之是最后留下了odds。）

好了，现在“对数”和“几率”都有了，就差一个“回归”。我们把线性回归（linear regression）的模型往上面一套：

$$\ln\dfrac{p}{1-p} = w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + \cdots + w_n \cdot x_n$$

再下面就是很简单的数学，中学那点水平足够：先把对数符号去掉。

$$\dfrac{p}{1-p} = e^{w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + \cdots + w_n \cdot x_n}$$

左右两边都取倒数。

$$\dfrac{1-p}{p} = e^{-(w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + \cdots + w_n \cdot x_n)}$$

左边分数化简一下。

$$\dfrac{1}{p} - 1 = e^{-(w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + \cdots + w_n \cdot x_n)}$$

把左边的$1$挪到右边去。

$$\dfrac{1}{p} = 1 + e^{-(w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + \cdots + w_n \cdot x_n)}$$

左右两边都取倒数，最后再把这个长长的连加，改成向量形式的内积，这就和大家在各种地方见到的“逻辑回归模型的预测”公式一样了，也就是最开始说的“$\omega$乘以$x$再激活”。

$$p = \dfrac{1}{1 + e^{-(w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + \cdots + w_n \cdot x_n)}} = \dfrac{1}{1 + e^{-w \cdot x}}$$

## 训练样本

前面提到了一共三个“先不管”，其实重点是这两个：（1）这些变量都是什么，代表什么含义，和具体业务有什么关系。（2）这些变量的权重，怎么通过训练的方法得到。

先说第一个，都有哪些变量，即，刚才看过的一大堆式子里面的带角标的$x$都是什么。

举广告场景下面的一个的例子吧（显然是造出来的例子）。比如某个广告系统，事先收集了大量的信息，包括：（1）用户的信息，例如每个用户的性别年龄。（2）广告的信息，例如广告的编号，广告是什么主题的，是卖衣服、卖车还是卖食品。（3）哪个用户在看哪个广告的时候有点击，在看哪个广告的时候没有点击。这些信息都拼在一起，各种变量（其实应该叫做“特征（feature）”）可以整理成下面的样子，每一行文本代表了业务系统里面经过了特征抽取（feature extraction）之后的一条日志，第一列是样本编号，第二列是是否点击，其余的是特征。

第一条样本，某位在读同学，没车没房，看到一款钻石广告，没有点击。第二条样本，某位企业家，有房没车，看到一款汽车广告，点击了。

> 123456,0,is_male,age_18_to_24,no_house,no_car,is_student,item_diamond,item_price_10w_to_100w,bias
> 123457,1,is_male,age_45_to_60,has_house,no_car,is_business,item_car,item_price_over_100w,bias

对应到公式里面，is_male这个特征在两条样本中都出现了，age_18_to_24只在第一条样本中出现，而age_45_to_60只在第二条样本中出现。最后我们生成的模型可能长这样（随便乱写的，不代表任何倾向性或者主观意见）：

> is_male 0.88
> is_female 0.92
> age_18_to_24 -0.12
> age_24_to_45 0.09
> age_45_to_64 -0.05

在模型训练完毕，进行线下评估或者线上预测的时候，只需要按照样本中出现的特征，从模型里面取对应的权重（模型可以看成是一个字典），然后按照公式进行计算。

顺便提一下“组合特征”。从线性回归的模型来看，它之所以有“解释性”，是因为每个特征的权重能直接影响预测结果。例如某个特征是“这是一个冰箱广告”的权重可能是$0.1$，另一个特征“这是一个玛莎拉蒂广告”的权重可能是$-1$，通常来说买冰箱的人比买玛莎拉蒂的人会多很多，所以权重高一些也是正常的。但是有的时候我们发现还需要一些复杂的特征，例如弄这样一个特征“用户当前是2G网络&&当前广告样式中不带视频”，再来一个“用户当前是2G网络&&当前广告样式中带有视频”，直观上想前者的权重应该比后面的大，因为大家在网络条件比较差的时候通常不会点击带视频的广告。如果模型中确实体现出了这种情况，那么当用户用2G网络进行搜索（凤巢广告），或者用2G网络上网（网盟广告），或者在2G网络下面刷feed流（百度APP广告），在计算广告点击率的时候，应该能明显发现带视频的广告的点击率会明显低（因为它会命中后面这个权重低的特征，导致整体计算出来的点击率偏低），然后排序的时候这种带视频的就会被排在后面就不会给用户展示。这看起来很合理，并且对用户体验也好。

然而难点在于，有这么多的特征，哪些和哪些需要组合，组合出来的数量会不会超级大。此外组合这件事情也不一定是两两组合，有的时候需要三个三个组合，或者是两个特征类可能出现的特征也不一定任意两个都要组合。这是一个专门需要做的事情，即传说中的特征工程（feature engineering）。

## 梯度下降

有一批机器学习的问题可以用著名的梯度下降法（gradient descent）来求解。举一个很俗但是确实清晰易懂的例子：一个人站在一个盆地上，可能是盆沿也可能是盆内，想走到盆底。这还不简单，先看一眼盆底在哪里，然后直接走过去就好了。呃，用人来举例子有点儿不太好说，因为人太聪明了。换一个。说有一个球放在脸盆内部的盆壁上，一松手，球就会自己向下滚然后滚到某个盆底的最低点不动了。问题来了，刚松手的时候，球怎么知道冲哪个方向滚？换到机器学习的场景来说，对于某些模型，比如LR模型，是有全局最优解的，但是对于拿到的一批训练样本，怎么得到这个最优解？

通常的方法是，先随机初始化一个模型（相当于瞎猜，肯定很烂），然后利用训练样本来“修正”这个模型，称之为迭代（iterate），当训练样本被计算了多次之后，模型会越变越好，直到迭代到足够轮数（遍历一遍全部样本叫做一轮，iteration或者pass或者epoch），或者满足了某一个收敛条件，就停止训练并且输出模型。梯度计算在这里起到了重要作用，也是通常机器学习算法中最消耗计算力的一个步骤。一个常见方法是每个计算者（worker）都随机取到一部分样本（mini-batch），计算这一部分样本在当前模型上面的梯度，然后发送给参数服务器（parameter server），参数服务器负责把收集到的梯度合并（merge）到模型上面。这种方法称之为随机梯度下降法（stochastic gradient descent）。

回到之前说的“小球放进盆里”的例子，小球开始随便放在脸盆内测的某个地方，它只能知道当前往哪边走可以变得位置更低，于是向那个方向稍微挪一点儿。然后再看看往哪边走会更低，再挪一点儿。因此我们的计算流程也是这样，先随机初始化一个模型，用一部分样本计算在当前模型上面的梯度，然后顺着梯度方向更新模型（移动一点点），然后再随机取一批样本，再计算梯度……如此反复。

## 损失函数和梯度计算

数学又来了。在知道了应用场景之后，我们开始考虑下一个问题，即这些权重从哪里来。按照机器学习的一般“套路”，最常见的方法之一是随机初始化，然后遍历样本进行梯度计算，然后迭代更新权重，反复更新，直到觉得模型差不多可以用了（收敛，converge）就停止。

要计算梯度，首先要有损失函数（cost function），要不然拿啥去求导数？问题变成了，我们要优化一个什么样的目标，即，给了一大堆样本的特征$x$（看成是一个高维向量）和一个标签$y$，怎么样才能体现出“模型准不准”呢？

先拿一条样本来说。拿到一个样本，根据公式计算出它被点击的概率，然后：

当这条样本的标签是$1$的时候，“正确分类的概率”就是按照公式计算出来的它被点击的概率，即：

$$P(y|x;w) = P(y=1|x;w)$$

当这条样本的标签是$0$的时候，“正确分类的概率”就是按照公式计算出来的它不被点击的概率，即：

$$P(y|x;w) = P(y=0|x;w) = 1 - P(y=1|x;w)$$

用一个神奇的方法，硬把两行弄进一行里面：

$$P(y|x;w) = P(y=1|x;w)^y \cdot (1 - P(y=1|x;w))^{1-y}$$

这是什么乱七八糟的，怎么连$y$都跑到角上去了？仔细想想好像还有点道理：当$y=1$的时候，后面一大坨的右上角是$0$所以整个没有了，只剩下前面。当$y=0$的时候，前面一大坨的右上角是$0$所以整个没有了，只剩下后面。这样就正好和我们前面写的那个当标签$1$怎么样，当标签$0$怎么样，是一个意思。

不错吧，一条样本的正确的概率出来了，再看看多条样本的时候？显然是把所有样本分对的概率都乘在一起嘛（样本之间相互独立（independent）的简化情况），不过这个时候就需要用角标来区分不同的样本了，于是损失函数是：

$$\prod\limits_{i=1}^{n}{P(y_i=1|x_i;w)^{y_i} \cdot (1 - P(y_i=1|x_i;w))^{1-y_i}}$$

连乘太麻烦了，不好弄，两边同时取个对数，把连乘变成连加。

$$L(w) = \sum\limits_{i=1}^{n}{ y_i \ln P(y_i=1|x_i;w) + (1-y_i) \ln (1 - P(y_i=1|x_i;w)) }$$

刚才前面已经说过这个概率怎么算：

$$P(y=1|x;w) = \dfrac{1}{1+e^{-w \cdot x}}$$

把它代入到我们的损失函数中，变得好长：

$$L(w) = \sum\limits_{i=1}^{n}{ y_i \ln \dfrac{1}{1+e^{-w \cdot x_i}} + (1-y_i) \ln (1 - \dfrac{1}{1+e^{-w \cdot x_i}}) }$$

只看求和符号里面的，看怎么能短一点儿：

第一项里面的分子分母同时乘以$e^{wx_i}$，第二项先把1给拆开成$\dfrac{1+e^{-w \cdot x_i}}{1+e^{-w \cdot x_i}}$。

$$= \sum\limits_{i=1}^{n}  y_i \ln \dfrac{e^{w \cdot x_i}}{e^{w \cdot x_i}+1} + (1-y_i) \ln \dfrac{e^{-w \cdot x_i}}{1+e^{-w \cdot x_i}}$$

第一项用$\ln \dfrac{a}{b}=\ln a-\ln b$拆开，第二项里面的分子分母同时乘以$e^{w \cdot x_i}$。

$$= \sum\limits_{i=1}^{n}  y_iw \cdot x_i - y_i \ln (1 + e^{w \cdot x_i}) + (1-y_i) \ln \dfrac{1}{e^{w \cdot x_i}+1}$$

第二项用$\ln\dfrac{1}{a}=-\ln a$改变一下符号。

$$= \sum\limits_{i=1}^{n}  y_iw \cdot x_i - y_i \ln (1+e^{w \cdot x_i}) + (y_i-1) \ln (1 + e^{w \cdot x_i})$$

把能抵消的都抵消掉。

$$= \sum\limits_{i=1}^{n}  y_iw \cdot x_i - \ln(1+e^{w \cdot x_i})$$

所以我们要求的模型，也就是最合适的$w$，就变成了这个样子：

$$w^{*} = \arg\limits_{w}\max L(w) = \arg\limits_{w}\min (-L(w)) = \arg\limits_{w}\min \sum\limits_{i=1}^{n}(\ln(1+e^{w \cdot x_i})-y_iw \cdot x_i)$$

计算导数：这里的$w \cdot x$表示$w$向量和$x$向量内积，对单个$w_j$求导数：

注意到$(\ln a)' = \dfrac{1}{a}$，并且$(e^a) ' = e^a$。

$$\dfrac{\partial L(w)}{\partial w_j} = \dfrac{1}{1+e^{w \cdot x}}e^{w \cdot x}x_j - y_i x_j = \dfrac{e^{w \cdot x}}{1+e^{w \cdot x}} x_j - y_i x_j = x_j(\dfrac{1}{1+e^{-w \cdot x}} - y_i)$$

所以算法出来了：对于某一条样本来说，先计算它的预测值，然后和标签相减，然后对于这条样本的每一个出现的特征，都记一次梯度的“贡献”。

## c++ code

上面获得的导数的形式倒是不太长（其实是很短），所以对应的c++代码长这样（从hippo的ftrl里面直接贴过来！）：

第一个片段，如何计算预测值。

{% highlight c++ %}
float_type LRTrainNode::sparse_pred(const Instance& ins) const {
    float_type ret = 0.0;
    for (auto& id : ins.ids) {
        // ensure that _pull_results has key id.
        ret += _sparse_weight.at(id);
    }
    return Util::sigmoid(ret);
}
{% endhighlight %}

第二个片段，如何计算梯度。

{% highlight c++ %}
for (const auto& ins : lines) {
    ctr = sparse_pred(ins);
    // ctr - label
    g = ctr - ins.label;
    for (auto& id : ins.ids) {
        lv.weight = g;
        lv.count = 1;
        if (!(_is_platform_data && !_pull_flags[id])) {
            update_vec.push_back(std::make_pair(id, lv));
        }
    }
    // ctr, show, click
    v.add_single_point(ctr, 1, ins.label);
}
{% endhighlight %}

## 损失函数2

在stackexchange和其它问答网站上面看到过一些提问，问为什么逻辑回归的损失函数有两个不同版本。一个是我们刚才用到的这个：

$$\sum\limits_{i=1}^{n}  y_iw \cdot x_i - \ln(1+e^{w \cdot x_i})$$

另一个看起来更短一些：

$$\sum\limits_{i=1}^{n}\ln(1+e^{-y_i(w \cdot x_i)})$$

那么区别在哪里，为什么会有两种不同的损失函数？答案是：我们刚才用的标签$y_i$，是$0$和$1$，而如果把$y_i$的取值范围改成$1$和$-1$，会怎样？

和以前一样，当样本标签是$1$的时候，“正确分类的概率”是：

$$P(y|x;w) = P(y=1|x;w) = \dfrac{1}{1+e^{-w \cdot x}}$$

当样本标签是$-1$的时候，“分类正确的概率”是：

$$P(y|x;w) = P(y=-1|x;w) = 1 - \dfrac{1}{1+e^{-w \cdot x}} = \dfrac{1+e^{-w \cdot x}}{1+e^{-w \cdot x}} - \dfrac{1}{1+e^{-w \cdot x}} = \dfrac{e^{-w \cdot x}}{1+e^{-w \cdot x}} = \dfrac{1}{1+e^{w \cdot x}}$$

仍然把两种不同情况硬揉在一起，不过这次简单了，标签是$1$和$-1$，所以把$y_i$直接写到$x$的旁边：

$$P(y|x;w) = \dfrac{1}{1+e^{-y_iw \cdot x}}$$

所以在样本独立的简化情况下，整体的损失函数是：

$$L(w) = \prod\limits_{i=1}^{n} \dfrac{1}{1+e^{-y_i(w \cdot x_i)}}$$

取完负对数（negative log likelihood）之后，就变成了最终的样子：

$$\sum_{i=1}^{n}\ln(1+e^{-y_iw \cdot x})$$
