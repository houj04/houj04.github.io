---
layout: post
title: "Germany Tank Problem"
categories: mypost
---

# Germany Tank Problem

[TOC]

## 背景

第二次世界大战（second world war）期间，盟军（allied forces）希望知道德国坦克的产量。传统的情报工作的确可以带来各种各样的信息，但是有些信息是互相矛盾并且不可信的。

后来有人在战场上摧毁和缴获的坦克上面找到了各种各样的编号，比如生产序号、发动机号、变速箱号，等等。用统计学的方法对这些数据进行了计算（很简单的计算！）之后，估计出了德国坦克生产情况的数据，当战后的真实数据披露之后，发现超乎预期地接近。

有数据显示，传统情报工作估计，从1940年6月到1942年9月期间，每个月大约有1400辆坦克被生产出来，但是通过序列号估计出来的值只有每月256辆。事后证明，真实的产量是255。

还有一些其它的数据如下表。

| 月份 | 用统计方法估计 | 根据情报估计 | 德军的记录 |
| - | - | - | - |
| 1940年6月 | 169 | 1000 | 122 |
| 1941年6月 | 244 | 1550 | 271 |
| 1942年8月 | 327 | 1550 | 342 |

## 数学期望

只考虑最简单的情况：“离散变量的数学期望，就是把离散值按照概率进行加权。”这句话是什么意思？

举个例子。

比如我们要摆一个摊卖彩票。彩票有一半的概率什么也不中，一半的概率中100元。那么，不考虑作弊，有大量玩家来玩，运气都差不多，那么这种情况下，每张彩票应该卖多少钱才收支平衡？

显然，应该卖50元。因为平均一个玩家能赚50元。

太简单了是吧，搞得稍微复杂一点。

每个玩家有$1/2$的概率什么也不中，有$1/3$的概率中3元，有$1/6$的概率中6元，那么每张彩票应该卖多少钱？应该是：

$$E(X) = \dfrac{1}{2} \cdot 0 + \dfrac{1}{3} \cdot 3 + \dfrac{1}{6} * 6 = 2$$

所以，对于一般情况，随机变量$x$的取值范围是$x_1, \ldots, x_n$，概率分别是$p_1, \ldots, p_n$，那么数学期望

$$E(X) = \sum_{i=1}^{n}p_ix_i$$

## 估算坦克总数

回到我们刚开始的话题上。假设总共有$N$辆坦克（未知），编号从$1$到$N$，中间不间断，都投放到战场上了。我们随机击毁或者俘虏了其中的$k$辆，其中编号最大的一辆是$m$，那么，如何通过$k$和$m$，估计总数$N$？

啥？这好像不科学吧，只给了两个数？

先看一个稍微简单一点的问题：已知总共有$N$辆坦克，随机从里面取$k$辆，那么编号最大的$m$的期望是多少？

按照我们前面说的关于“期望”的概念，只要这样算就行了：

$$E = \sum_{m=1}^{N}m\cdot p(m) = \sum_{m=1}^{N} m \cdot “最大的编号恰好是m”这件事情的概率$$

问题瞬间转化成了，怎么求这个概率。即，“从$1$到$N$中随机取$k$个，其中最大值恰为$m$的概率”。这是一个典型的“古典概型”的问题。

怎么又来一个词。古典概型就是最通常意义上的概率模型，它有两个特点：（1）有限性，所有可能出现的基本事件只有有限个；（2）等可能性，每个基本事件出现的可能性相等。所以套过来就是，“取$k$个”的可能性肯定是有限个（虽然可能很多），并且随机取的话，每种可能性出现的概率都一样。

于是回到了中学或者大学低年级时候我们熟悉的排列组合问题：

问题1：从$N$个里面随机取$k$个，有多少种取法？这个简单，直接照着定义：

$$\dbinom{N}{k}$$

问题2：从$N$个里面随机取$k$个，并且最大值是$m$，有多少种取法？取法是，先取一个$m$出来，剩下$k-1$都从$m-1$及以下取，所以是

$$\dbinom{m-1}{k-1}$$

上面两个问题得到的答案一除，再和之前的关于期望的那个公式合并：

注意求和的起点，由于我们选择了$k$个，所以$m$至少也是$k$。

$$E = \sum_{m=k}^{N} m \cdot \dfrac{\dbinom{m-1}{k-1}}{\dbinom{N}{k}}$$

回忆一下二项分布的组合数计算：

$$\dbinom{n}{k} = \dfrac{n!}{k!(n-k)!}$$

所以

$$E = \sum_{m=k}^{N}m \cdot \dfrac{ \dfrac{(m-1)!}{(k-1)!(m-k)!} }{ \dfrac{N!}{k!(N-k)!} } = \sum_{m=k}^{N}m\dfrac{(m-1)!k!(N-k)!}{(k-1)!(m-k)!N!} $$

这是一大堆什么乱七八糟的，阶乘已经很麻烦了，怎么还有阶乘的求和。

首先注意到分子有一个$k!$，分母有一个$(k-1)!$，这俩抵消掉之后只剩一个$k$。此外还有一些明显是可以先从求和号里面拿出来的，把它们拿出来：

$$ E = \dfrac{k(N-k)!}{N!} \sum_{m=k}^{N} \dfrac{m!}{(m-k)!} $$

好像还是很长。不过有这样一个东西，叫做Hockey-stick identity，长这样：

$$\sum_{i=r}^{n} \dbinom{i}{r} = \dbinom{n+1}{r+1} $$

这个恒等式的左半部分也是有一个求和，和我们上面那个讨厌的求和，好像长得很像但是还差一点，差在哪儿？稍微变形一下就看出来了：

$$\dbinom{n+1}{r+1} = \sum_{i=r}^{n} \dbinom{i}{r} = \sum_{i=r}^{n} \dfrac{i!}{r!(i-r)!} = \dfrac{1}{r!}\sum_{i=r}^{n}\dfrac{i!}{(i-r)!}$$

这下，求和号里面的东西，和我们上面$E$的求和号里面的就一样了，只是字母稍微换一下。所以：

$$E = \dfrac{k(N-k)!}{N!} \cdot k!\dbinom{N+1}{k+1} = \dfrac{k\cdot k!(N-k)!}{N!} \dfrac{(N+1)!}{(k+1)!(N-k)!} = \dfrac{k(N+1)}{k+1}$$

居然那么多东西都互相抵消掉了，只剩下很简单的形式。我们求的是$m$的期望，所以干脆写成这样：

$$m = \dfrac{k(N+1)}{k+1} $$

有了这个式子之后，反过来求$N$也就很容易了，把上式里面的$k$挪到$m$那边去，于是：

$$N = \dfrac{m(k+1)}{k} - 1 = m(1+k^{-1})-1$$

## 实验

上面我们得到了一个看起来超简单的式子，不知道它科学不？随便弄点数据，写段代码跑跑看。

{% highlight c++ %}
#include <iostream>
#include <vector>
#include <algorithm>
#include <random>

const int MAX_TANK_COUNT = 500;
const int DESTROY_COUNT = 10;

std::vector<int> g_tanks;

double estimate(int tank_count) {
    static std::random_device rd;
    static std::mt19937 g(rd());
    g_tanks.push_back(tank_count);
    std::shuffle(g_tanks.begin(), g_tanks.end(), g);
    int max_id = *std::max_element(g_tanks.begin(), g_tanks.begin() + DESTROY_COUNT);
    return 1.0 * max_id * (1.0 + 1.0 / DESTROY_COUNT) - 1.0;
}

int main() {
    for (int i = 0; i < DESTROY_COUNT; i++) {
        g_tanks.push_back(i);
    }
    for (int tank_count = DESTROY_COUNT; tank_count < MAX_TANK_COUNT; ++tank_count) {
        std::cout << tank_count << "\t" << estimate(tank_count) << std::endl;
    }
    return 0;
}
{% endhighlight %}

代码跑出来的结果用matlab或者excel或者随便一个什么工具都能画出图来，可以看到整体上随着目标坦克数量$N$的增加，预测值也整体增加，并且差距并不很大，至少比之前看到的历史上通过传统情报推断出来的差好几倍的情况要好。
