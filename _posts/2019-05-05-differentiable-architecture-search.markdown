---
layout: post
title: "Differentiable Architecture Search"
categories: mypost
---

# Differentiable Architecture Search

## 论文介绍

* 文章标题：DARTS: Differentiable Architecture Search
* 作者：Hanxiao Liu, Karen Simonyan, Yiming Yang
* 发表于：ICLR 2019
* 参考：https://arxiv.org/abs/1806.09055

## 摘要

本文针对结构搜索（architecture search）的可扩展性（scalability）挑战进行了研究，用一种可微（differentiable）的方式对任务进行了公式化（formulate）。和传统的一些基于进化算法（evolution）或者是强化学习（reinforcement learning），在一个离散（discrete）的不可微的空间上进行搜索的方法不同，作者们的方法是对结构进行了连续的松弛（continuous relaxation）表示，因此可以使用梯度下降法（gradient descent）进行高效率的搜索。作者们在CIFAR-10、ImageNet、Penn Treebank和WikiText-2数据集上进行了详细的实验，结果显示作者们新提出的方法可以在图像分类（image classification）任务上搜索得到好的卷积（convolution）结构，可以在语言模型（language model）上获得好的循环（recurrent）结构，同时比之前的不可微的方法快若干个数量级。作者们的代码已经对外开源，可以供业界用来对高效的搜索方法进行进一步的研究。

## 1 介绍

探索先进的神经网络结构需要人类专家的大量工作。近一段时间，有一类用算法来自动化解决手工结构设计的研究，越来越多被人们所关注。这些自动化搜索得到的网络结构在图像分类和目标检测（object detection）任务上已经获得了非常有竞争力的表现。

目前最好的结构搜索算法尽管结果很好，但是需要大量的计算资源。例如，获得一个在CIFAR-10和ImageNet数据集上的达到领先水平的结构，需要大约2000个GPU日（使用强化学习方法）或者3150个GPU日（采用进化方法）。有人提出了一些用于加速的方法，例如搜索空间中的一个特殊的结构，或者是对每一个单独的结构进行性能预测，还有跨多个结构的权重共享或者是继承。但是关于可扩展性的根本挑战并没有解决。现有的多个方法，之所以不够高效，是因为不论基于强化学习的，基于进化的，基于MCTS的，基于SMBO的，基于贝叶斯优化（Bayesian optimization）的，其根本原因是它们都把结构搜索这个问题当成是一个黑盒（black-box）的优化问题，在一个离散的域上进行求解，因此导致了需要对非常多的结构进行评估（evaluation）。

在本文中，作者们从不同的角度对问题进行了研究，并且提出了一个高效率的结构搜索方法，称为DARTS（Differentiable ARchiTecture Search）。和传统的在一个离散的候选集上进行搜索的方法不同，作者们将搜索空间放松到了连续空间上，因此要搜索的结构可以按照它的验证集效果进行梯度下降法的求解。这种基于梯度下降法的优化方法，和传统的低效率的黑盒搜索相比较，使得DARTS能够获得和当前最好效果接近的性能，同时使用的计算资源量少了几个数量级。它也比近期提出的高效结构搜索方法ENAS要好。值得注意的是，DARTS比许多现有方法要简单，因为它不需要控制器（controller）、超网络（hypernetwork），也不需要性能预测工具（performance predictor），所以它可以足够通用，可以处理卷积结构以及循环结构。

在连续域上进行结构搜索的想法并不是新的，但是和之前的工作有几个明显的区别。前人的工作尝试去对一种结构进行一类特殊的微调（fine-tune），例如一个卷积神经网络的过滤器的形状（filter shape）或者是分支的模式（branch pattern）。而DARTS则可以在一个丰富的搜索空间中，学到高质量的，图结构复杂的结构组成模块。更进一步，DARTS并没有限制在任何的结构家族中，可以应用到卷积网络和循环网络中。

在作者们的实验中（原文第3节），DARTS可以设计出一个卷积计算单元，在图像分类的CIFAR-10数据集上，使用3.3M个参数，获得2.76$\pm$0.09%的错误率，这个和目前最好的使用了正则化的进化算法相当，但是节约了3个数量级的计算资源。同样的卷积计算单元在迁移到ImageNet（移动版）上获得了26.7%的top-1错误率，这个和最好的基于强化学习比较接近。在语言模型任务上，DARTS高效搜索到了一个循环计算单元，在Penn Treebank（PTB）数据集上获得了55.7的测试集混淆度（perplexity），超过了仔细调参之后的LSTM，以及所有的基于NAS和ENAS的自动搜索出来的计算单元。

本文的贡献可以总结成下面几条：

1、作者们提出了一个新的，基于两次优化（bilevel optimization）的，可微的，网络结构搜索算法，可以应用于卷积和循环网络。

2、作者们在图像分类和语言模型任务上进行了实验，证明基于梯度的网络结构搜索方法，可以在CIFAR-10数据集上获得有很高竞争力的结果，并且在PTB数据集上获得了超越前人的结果。这是一个非常有意思的结论，考虑到前人基于强化学习或者进化算法得到各种非可微的搜索技术所获得的所有最好的模型。

3、通过提出的基于梯度的优化方法，和传统的非可微搜索技术相比，作者们获得了可观的效率提升（将搜索所需要的时间降低到几个GPU日）。

4、作者们展示了用DARTS在CIFAR-10和PTB上搜索得到的结构，可以分别迁移到ImageNet和WikiText-2上。

作者们所实现的DARTS算法的代码，在github上面开源了：https://github.com/quark0/darts。

## 2 可微的结构搜索

2.1节将从整体上描述搜索空间。这里的一个结构（或者说一个具体的计算单元（cell））的计算流程用一个有向无环图（directed acyclic graph）描述。然后介绍一个简单的连续的松弛策略用在搜索空间上，可以转换成一个可微的优化目标，对网络结构和权重进行联合优化（joint optimization）（节3.2）。最后，提出一个近似技术，使得这个算法从计算上可行并且高效（节2.3）。

### 2.1 搜索空间

参考前人的一些做法，作者们实际搜索的是一个计算单元（computation cell），用来作为组建构成最终的结构。通过学习得到的计算单元可以以堆叠（stack）的方式构成一个卷积神经网络，或递归连接来构建一个循环神经网络。

一个计算单元是一个有向无环图，包括有序的$N$个节点。每个节点$x^{(i)}$是一个潜在表示（latent representation）（例如，可以是卷积神经网络里面的一个特征映射（feature map）），每一个有向边（directed edge）$(i,j)$和一个操作（operation）$o^{(i,j)}$关联，作用于$x^{(i)}$上。作者们假设每个计算单元有两个输入节点和一个输出节点。对于卷积单元来说，输入节点是前两层（layer）的输出。对于循环单元来说，输入节点是当前步（step）以及从前一个步带来的状态（state）。计算单元的输出是把所有的中间节点应用一个归并（reduction）操作（例如，连接（concatenation））。

每一个中间节点的计算，都是要基于所有排在它前面的节点：

$$ x^{(j)} = \sum_{i<j}o^{(i,j)}(x^{(i)}) $$

引入一个特殊的“零（zero）”操作，用来指示两个节点之间缺少连接的情况。这样一来，学习计算单元的任务，就简化成了学习每条边上的操作。

### 2.2 连续松弛和优化

用$O$来表示一系列候选操作（例如，卷积，最大池化（max pooling），零），里面每个操作都表示一个会作用于$x^{(i)}$上面的函数$o(\cdot)$。为了让搜索空间是连续的，作者们将这种“每一个操作都是一个多类别选其一（categorical choice）”的情况，转换成一个在所有可能的操作中的softmax操作：

$$o^{(i,j)}(x) = \sum_{o\in O}\dfrac{exp(\alpha_o^{(i,j)})}{\sum_{o'\in O}exp(\alpha_o^{(i,j)})}o(x)$$

上式中，两个节点$(i,j)$中间的权重（weight）是由一个$\|O\|$维的向量$\alpha^{(i,j)}$来作为参数的。因此结构搜索的任务进一步简化成为学习一系列的连续变量$\alpha = \{ \alpha^{(i,j)} \} $。在搜索结束之后，可以将每个混合的操作$o^{(i,j)}$按照最可能的操作来进行离散化，也就是$o^{(i,j)}=\arg\max_{o\in O}\alpha_o^{(i,j)}$。在后面的章节中，作者们用$\alpha$来表示网络结构的编码（encoding）。

在松弛之后，目标变成了同时学习网络结构$\alpha$和这些混合操作中的权重$w$（例如卷积过滤器（convolution filter）中的权重）。和其它的基于强化学习和进化算法的结构搜索相似的是，它们用验证集上的表现来当作奖励（reward）或者匹配度（fitness），DARTS也是要优化验证集上的损失，但用的却是梯度下降。

用$L_{train}$和$L_{val}$来分别表示训练集和验证集上的损失。这两个损失都是除了由结构$\alpha$确定，还由权重$w$确定。结构搜索的目标是找到一个$\alpha^{\*}$使得验证集上的损失$L_{val}(w^\*, \alpha^\*)$最小，而这里的权重$w^\*$又是和网络结构相关联，结构是通过最小化训练误差得到的，也就是$w^{\*}=\arg\min_wL_{train}(w,\alpha^{\*})$。

这就变成了一个双层优化（bilevel optimization）问题，上层变量是$\alpha$，下层变量是$w$：

$$\min_\alpha L_{val}(w^{*}(\alpha), \alpha)$$

$$s.t. w^{*}(\alpha) = \arg\min_wL_{train}(w,\alpha)$$

这种嵌套问题在基于梯度的超参数优化（hyperparameter optimization）问题中也有出现，可以把$\alpha$看成是超参数的一种特殊类型，尽管它的维度实际上会比传统意义上的标量超参数（例如，学习率（learning rate））要大，因此也更难优化。

### 2.3 近似结构梯度

完全准确地计算结构的梯度，由于内层优化的高复杂性，基本是不可能做到的。因此作者们提出了一种简单的近似方法：

$$\nabla_\alpha L_{val}(w^*(\alpha),\alpha)$$

$$ \approx \nabla_\alpha L_{val}(w-\xi\nabla_wL_{train}(w,\alpha),\alpha)$$

这里$w$表示算法所维护的当前的权重，$\xi$表示内层优化的一步的学习率。主要的思路是通过调整$w$的方式，对$w^*(\alpha)$进行近似，只用单一的训练步，而不需要将式4的整个内层优化完整的训练直到收敛（convergence）。注意如果$w$已经是一个内层优化的一个局部最优点，那么式6可以简化成为$\nabla_\alpha L_{val}(w, \alpha)$，然后$\nabla_wL_{train}(w,\alpha)=0$。

迭代的过程可以在原文的图1中看到。作者们目前还没有办法证明提出的算法的收敛性质，但是从实际情况来看，给定一个合适的$\xi$，是可以收敛到一个稳定点的。作者们还注意到动量项（momentum）在权重优化的时候如果使用，单步的展开的目标（式6）也要对应修改。

将链式法则（chain rule）应用到近似结构梯度（式6）中，得到

$$\nabla_\alpha L_{val}(w',\alpha)-\xi\nabla^2_{\alpha, w}L_{train}(w, \alpha)\nabla_{w'}L_{val}(w',\alpha)$$

这里$w'=w-\xi\nabla_wL_{train}(w,\alpha)$表示单步前向模型的权重。上面这个表达式还包含了一个复杂的矩阵和向量乘积操作（它的第二项）。幸运的是，这种复杂度实质上可以简化掉，用有限差分近似/逼近（finite difference approximation）。记$\epsilon$是一个很小的标量，以及$w^{\pm}=w\pm\epsilon\nabla_{w'}L_{val}(w',\alpha)$。那么：

$$\nabla^2_{\alpha , w}L_{train}(w, \alpha )\nabla_{w'}L_{val}(w', \alpha) \approx \dfrac{\nabla_\alpha L_{train}(w^+,\alpha)-\nabla_\alpha L_{train}(w^-,\alpha )}{2\epsilon}$$

计算上面的差分只需要两遍对权重的前向过程，和两遍对$\alpha$的后向过程，因此复杂度从$O( \|    \alpha  \| \| w \| )$降低到了$O( \| \alpha \| + \| w \| )$。

一阶优化：当$\xi = 0 $的时候，式7中的二阶导数会消失。在这种情况下，结构的梯度是$\nabla_\alpha L_{val}(w, \alpha)$，这恰好和“按照简单的启发式的优化验证集损失的思路，假设当前的$w$和$w^*(\alpha)$一样”能对上。这就带来了一些用效果换速度的方法，可以参考原文中表1和表2的实验部分。在文中后面的部分，作者们把$\xi=0 $称为一阶优化，把梯度公式中$\xi>0$称为二阶优化。

## 2.4 获得离散结构

为了构造出离散结构中的每个节点，作者们保留了每个节点中，从全部的前序节点获得的非零的候选操作里面的$k$个最强的。一个操作的“强度”定义为$\dfrac{exp(\alpha_0^{(i,j)})}{\sum_{o'\in O}exp(\alpha_{o'}^{(i,j)})}$。为了让生成的结构和已有工作近似，作者们对卷积单元选择了$k=2$，对循环单元选择了$k=1$。

“零”操作被排除在外，有两个原因。第一个，为了和现有的工作能够进行平等的对比，需要恰好$k$个非零的输入边。第二个，零操作的强度是无法确定的，因为加大零操作的分对数（logit）只会影响结果节点的表示范围（scale），由于批归一化（batch normalization）的存在，不会影响最终的分类结果。

























