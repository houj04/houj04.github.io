---
layout: post
title: "Quantize a Float Value"
categories: mypost
---

## 背景

在模型压缩（model compression）中，通常需要对模型的权重（weight）或者是梯度（gradient）进行量化（quantization）。在目前所见到的各种训练工具中，无论是开源工具或者是已知的某些闭源工具，（显然）权重和梯度都使用浮点数（floating-point）进行计算的。而模型压缩的作用则是减少模型中权重的冗余，其中一类做法是降低模型存储数值的精度。

这里只介绍一些对于浮点数进行压缩操作的简易方法。

## 浮点数的表示

在多数大学的计算机系本科生低年纪课程中都会介绍浮点数的一般表示，即IEEE754标准。本文以下的部分主要参考[维基百科对于单精度浮点数的介绍](https://en.wikipedia.org/wiki/Single-precision_floating-point_format)。

一个单精度浮点数的二进制表示（single-precision binary floating-point format），一共有4字节（byte），32比特（bit）。即C或者C++语言中的

> sizeof(float) = 4

为了能够表示很大范围的数，在浮点数的表示形式中，采用了符号+指数+尾数的形式。指数用来管理范围，尾数用来管理精度，这样可以兼顾范围和精度，同时带来的缺点是，如果我们真正需要使用的数值，不需要这么大的范围，或者不需要这么高的精度，就会产生一定的浪费（这也就是为什么做模型压缩的时候可以在“浮点数的表示”上面想办法）。

这32个bit的分布是1+8+23，即：1bit符号位（sign），8bit指数位（exponent），23bit尾数（fraction，significand或者叫做mantissa）。在浮点数的正常表示中，为了节约空间，会将被表示的数的绝对值，表示成下面的形式：

$$ value = (-1)^{sign} \times 2^{x - 127} \times (1.y)_2 $$

看起来有点奇怪，但是按照下面的思路一点一点看过去，会觉得挺符合直观：

（1）首先需要1个bit来保存正负号。

（2）如果一个数太大或者太小（指绝对值），就先把它“靠近”成2的若干次方，记录一下这个“次方”（即，指数），然后剩余部分，看看它和这个“次方”差多少，表示成“尾数”。

（3）考虑到在步骤2中的“次方”可能是正的也可能是负的，干脆都加上127，这样就都是正的了。

（4）如果在步骤2中，选择“次方”的时候总是选择一个比原数绝对值小的，那么尾数一定大于1，肯定是1.abcdefg的形式，那么这个“1.”也就不用存了，只存后面的abcdefg即可。

完整的三个部分的作用介绍如下：

符号位：1bit。当它是0的时候表示这个浮点数是0或者正数，当它是1的时候表示这个浮点数是负数。

指数位：8bit。首先有一些特殊情况：当指数是0x00并且后面的尾数也是0，那么表示0（汗，全0的可不就是0嘛）。当指数是0x
，但是后面的尾数不是0，说明这个浮点数是非规格化浮点数（denormal number），用来表示绝对值非常小，非常接近于0的数。当指数是0xFF的时候，说明整个数是无穷大或者是NaN（not a number）。剩余的情况，也就是指数在0x01到0xFE之间，是正常的一般的情况，即规格化浮点数。

尾数位：23bit。主要的精度贡献者。在正常情况下表示一个规格化浮点数的尾数（即，上面的步骤4中提到的1.abcdefg中的abcdefg），在非规格化浮点数中就没有那个“1.”了（说明此时的value值太小，指数已经是0了（+127之后是0，这得有多小啊），然后此时还不能保证尾数能写成“1.”开头）。

参考维基百科上面的一个例子来说明：某数的32个bit分别如下：

| sign | exponent | fraction |
| :-: | :-: | :-: |
| 0 | 01111100 | 01000000000000000000000 |

那么该数的数值为

$$ (-1)^0 \times 2^{0\text{x}01111100 - 127} \times (1.01)_2 = 2^{124 - 127} * (1 + 0.25) = 0.15625 $$

## 对浮点数的量化

首先是一些一般的量化方法，并不局限于浮点数，简要列举如下：

1、最大最小（max-min）法：即对一批（注意是一批）需要被量化的数值，首先计算出其最大值和最小值，然后

$$ new\_value = \dfrac{old\_value - min}{max - min} $$

这样计算出来的结果就会变成一个小于1的浮点数，然后可以再均匀拉伸到某个证书区间，例如乘以65536然后取整，等等。

2、绝对值最大（abs max）法：对于一批需要被量化的数值，找到它们中绝对值最大的那个，然后

$$ new\_value = \dfrac{old\_value}{abs\_max} $$

该方法可以使得输入为0的时候输出仍是0，因此对于乘法操作而言（在神经网络的计算中，乘法是必须要支持的），下面的式子在选择了合适的伸缩因子的时候是可以成立的。

$$ scale(A) \times scale(B) = scale(A \times B) $$

作为对比，注意方法1的操作，是不能直接用于乘法的，不能找到一个简单如上式的方法来进行反量化。

然后是针对特定浮点数的操作：

针对指数：如果认为默认的指数（8bit）精度太高，那么需要设定一个新的指数范围。例如，默认的指数是8bit，因此可以用来表示正常数值的范围是0x01到0xFE，也就是1到254。减去127之后得到了真实范围是-126到127。那么对于自定义的裁剪之后的指数也类似，裁剪到7bit的话，新的范围是-62到63。所以量化的方法是：首先减去127，得到真实的指数。如果大于63，那么就设置为63。如果小于-62，那么就设置为-62。

针对尾数：如果认为默认的尾数（23bit）精度太高，希望设置为7bit，那么只需要将末尾16个bit置零即可。最简单的做法是和0xFFFF0000进行一个“与（and）”操作。
